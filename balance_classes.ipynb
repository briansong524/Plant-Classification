{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import numpy.core.defchararray as np_string\n",
    "import pandas as pd\n",
    "\n",
    "import glob\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_dir = os.getcwd() \n",
    "train_dir = work_dir + '/train/'\n",
    "test_dir = work_dir + '/test/'\n",
    "model_path = work_dir + '/model/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sugar beet', 'Common Chickweed', 'Cleavers', 'Shepherds Purse', 'Charlock', 'Common wheat', 'Small-flowered Cranesbill', 'Loose Silky-bent', 'Scentless Mayweed', 'Fat Hen', 'Maize', 'Black-grass']\n"
     ]
    }
   ],
   "source": [
    "list_paths = glob.glob(train_dir + '*')\n",
    "list_names = [i.replace(train_dir,'') for i in list_paths]\n",
    "print(list_names)\n",
    "name2ind = dict(zip(list_names, range(len(list_names))))\n",
    "ind2name = dict(zip(range(len(list_names)),list_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sugar beet: 385 pictures\n",
      "Common Chickweed: 611 pictures\n",
      "Cleavers: 287 pictures\n",
      "Shepherds Purse: 231 pictures\n",
      "Charlock: 390 pictures\n",
      "Common wheat: 221 pictures\n",
      "Small-flowered Cranesbill: 496 pictures\n",
      "Loose Silky-bent: 654 pictures\n",
      "Scentless Mayweed: 516 pictures\n",
      "Fat Hen: 475 pictures\n",
      "Maize: 221 pictures\n",
      "Black-grass: 263 pictures\n"
     ]
    }
   ],
   "source": [
    "for i in list_names:\n",
    "    print(i + ': ' + str(len(os.listdir(train_dir + i))) + ' pictures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = list()\n",
    "train_label_list = list()\n",
    "test_set = list()\n",
    "test_label_list = list()\n",
    "\n",
    "for i in list_names:\n",
    "    glob_per_dir = glob.glob(train_dir + i + '/*')\n",
    "    n_plants = len(glob_per_dir)\n",
    "    n_train = int(np.round(0.8*n_plants))\n",
    "    train_path_per_glob = random.sample(glob_per_dir, n_train)\n",
    "    test_path_per_glob = list(set(glob_per_dir) - set(train_path_per_glob))\n",
    "    train_set.extend(train_path_per_glob)\n",
    "    test_set.extend(test_path_per_glob)\n",
    "    train_label_list.extend([i]*n_train)\n",
    "    test_label_list.extend([i]*(len(glob_per_dir) - n_train))\n",
    "    \n",
    "train_label = [name2ind[i] for i in train_label_list]\n",
    "test_label = [name2ind[i] for i in test_label_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label_for_cm = test_label.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsong/venv/py3/lib/python3.5/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/home/bsong/venv/py3/lib/python3.5/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    }
   ],
   "source": [
    "from skimage.transform import resize as imresize\n",
    "import imageio\n",
    "\n",
    "def img_reshape(img):\n",
    "    img = imresize(img, (51, 51, 3))\n",
    "    return img\n",
    "\n",
    "def img_get(path):\n",
    "    img = imageio.imread(path)\n",
    "    img = img_reshape(img)\n",
    "    return img\n",
    "train_img = [img_get(i) for i in train_set]\n",
    "test_img = [img_get(i) for i in test_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3801 3801\n"
     ]
    }
   ],
   "source": [
    "print(len(train_img), len(train_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, Input\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "import keras.backend as K\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "# Dense layers set\n",
    "def dense_set(inp_layer, n, activation, drop_rate=0.):\n",
    "    dp = Dropout(drop_rate)(inp_layer)\n",
    "    dns = Dense(n)(dp)\n",
    "    bn = BatchNormalization(axis=-1)(dns)\n",
    "    act = Activation(activation=activation)(bn)\n",
    "    return act\n",
    "\n",
    "# Conv. layers set\n",
    "def conv_layer(feature_batch, feature_map, kernel_size=(3, 3),strides=(1,1), zp_flag=False):\n",
    "    if zp_flag:\n",
    "        zp = ZeroPadding2D((1,1))(feature_batch)\n",
    "    else:\n",
    "        zp = feature_batch\n",
    "    conv = Conv2D(filters=feature_map, kernel_size=kernel_size, strides=strides)(zp)\n",
    "    bn = BatchNormalization(axis=3)(conv)\n",
    "    act = LeakyReLU(1/10)(bn)\n",
    "    return act\n",
    "\n",
    "# simple model \n",
    "def get_model():\n",
    "    inp_img = Input(shape=(51, 51, 3))\n",
    "\n",
    "    # 51\n",
    "    conv1 = conv_layer(inp_img, 64, zp_flag=False)\n",
    "    conv2 = conv_layer(conv1, 64, zp_flag=False)\n",
    "    mp1 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2))(conv2)\n",
    "    # 23\n",
    "    conv3 = conv_layer(mp1, 128, zp_flag=False)\n",
    "    conv4 = conv_layer(conv3, 128, zp_flag=False)\n",
    "    mp2 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2))(conv4)\n",
    "    # 9\n",
    "    conv7 = conv_layer(mp2, 256, zp_flag=False)\n",
    "    conv8 = conv_layer(conv7, 256, zp_flag=False)\n",
    "    conv9 = conv_layer(conv8, 256, zp_flag=False)\n",
    "    mp3 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2))(conv9)\n",
    "    # 1\n",
    "    # dense layers\n",
    "    flt = Flatten()(mp3)\n",
    "    ds1 = dense_set(flt, 128, activation='tanh')\n",
    "    out = dense_set(ds1, 12, activation='softmax')\n",
    "\n",
    "    model = Model(inputs=inp_img, outputs=out)\n",
    "    \n",
    "    # The first 50 epochs are used by Adam opt.\n",
    "    # Then 30 epochs are used by SGD opt.\n",
    "    \n",
    "    #mypotim = Adam(lr=2 * 1e-3, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "    mypotim = SGD(lr=1 * 1e-1, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                   optimizer=mypotim,\n",
    "                   metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "#model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "train_img = np.array(train_img)\n",
    "test_img = np.array(test_img)\n",
    "train_label = to_categorical(np.array(train_label))\n",
    "test_label = to_categorical(np.array(test_label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = dict(zip(range(len(list_names)), [1]*len(list_names)))\n",
    "class_weights[7] = 1.5\n",
    "class_weights[11] = 3\n",
    "class_weights[2] = 1.3\n",
    "class_weights[4] = .9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 15\n",
    "RANDOM_STATE = 11\n",
    "\n",
    "def get_callbacks(filepath, patience=5):\n",
    "    lr_reduce = ReduceLROnPlateau(monitor='val_acc', factor=0.1, min_delta=1e-5, patience=patience, verbose=1)\n",
    "    msave = ModelCheckpoint(filepath, save_best_only=True)\n",
    "    return [lr_reduce, msave]\n",
    "\n",
    "def train_model(xtr,ytr,xte,yte, model_path, start_ = 'new'):\n",
    "    \n",
    "    callbacks = get_callbacks(filepath = model_path + 'model_weight_SGD.hdf5', patience = 3)\n",
    "    model_ = get_model()\n",
    "    if start_ == 'update':\n",
    "        model_.load_weights(filepath = model_path + 'model_weight_SGD.hdf5')\n",
    "    gen = ImageDataGenerator(\n",
    "            rotation_range=360.,\n",
    "            width_shift_range=0.3,\n",
    "            height_shift_range=0.3,\n",
    "            horizontal_flip=True,\n",
    "            vertical_flip=True\n",
    "            )#zoom_range=0.3,\n",
    "            \n",
    "    \n",
    "#     model_.fit_generator(gen.flow(xtr,ytr, batch_size = BATCH_SIZE),\n",
    "#                        steps_per_epoch=10*len(xtr)/BATCH_SIZE,\n",
    "#                        epochs=EPOCHS,\n",
    "#                        verbose=1,\n",
    "#                        shuffle=True,\n",
    "#                        validation_data=(xte, yte),\n",
    "#                        callbacks=callbacks)\n",
    "    \n",
    "    model_.fit_generator(gen.flow(xtr, ytr, batch_size = BATCH_SIZE),\n",
    "                   steps_per_epoch=10*len(xtr)/BATCH_SIZE,\n",
    "                   epochs=EPOCHS,\n",
    "                   verbose=1,\n",
    "                   shuffle=True,\n",
    "                   validation_data=gen.flow(xte, yte, batch_size = BATCH_SIZE),\n",
    "                   validation_steps=len(xte) / BATCH_SIZE,\n",
    "                   callbacks=callbacks,\n",
    "                   class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_24 (InputLayer)        (None, 51, 51, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_162 (Conv2D)          (None, 49, 49, 64)        1792      \n",
      "_________________________________________________________________\n",
      "batch_normalization_208 (Bat (None, 49, 49, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_162 (LeakyReLU)  (None, 49, 49, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_163 (Conv2D)          (None, 47, 47, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_209 (Bat (None, 47, 47, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_163 (LeakyReLU)  (None, 47, 47, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_70 (MaxPooling (None, 23, 23, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_164 (Conv2D)          (None, 21, 21, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_210 (Bat (None, 21, 21, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_164 (LeakyReLU)  (None, 21, 21, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_165 (Conv2D)          (None, 19, 19, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_211 (Bat (None, 19, 19, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_165 (LeakyReLU)  (None, 19, 19, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_71 (MaxPooling (None, 9, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_166 (Conv2D)          (None, 7, 7, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_212 (Bat (None, 7, 7, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_166 (LeakyReLU)  (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_167 (Conv2D)          (None, 5, 5, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_213 (Bat (None, 5, 5, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_167 (LeakyReLU)  (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_168 (Conv2D)          (None, 3, 3, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_214 (Bat (None, 3, 3, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_168 (LeakyReLU)  (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_72 (MaxPooling (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_24 (Flatten)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_47 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_215 (Bat (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_48 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 12)                1548      \n",
      "_________________________________________________________________\n",
      "batch_normalization_216 (Bat (None, 12)                48        \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 12)                0         \n",
      "=================================================================\n",
      "Total params: 1,775,100\n",
      "Trainable params: 1,772,516\n",
      "Non-trainable params: 2,584\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "1188/1187 [==============================] - 30s 25ms/step - loss: 0.1029 - acc: 0.9772 - val_loss: 0.2037 - val_acc: 0.9389\n",
      "Epoch 2/15\n",
      "1188/1187 [==============================] - 23s 20ms/step - loss: 0.0810 - acc: 0.9821 - val_loss: 0.1898 - val_acc: 0.9410\n",
      "Epoch 3/15\n",
      "1188/1187 [==============================] - 23s 19ms/step - loss: 0.0751 - acc: 0.9836 - val_loss: 0.1525 - val_acc: 0.9484\n",
      "Epoch 4/15\n",
      "1188/1187 [==============================] - 23s 19ms/step - loss: 0.0685 - acc: 0.9850 - val_loss: 0.2941 - val_acc: 0.9199\n",
      "Epoch 5/15\n",
      "1188/1187 [==============================] - 23s 19ms/step - loss: 0.0641 - acc: 0.9866 - val_loss: 0.1718 - val_acc: 0.9505\n",
      "Epoch 6/15\n",
      "1188/1187 [==============================] - 23s 19ms/step - loss: 0.0599 - acc: 0.9872 - val_loss: 0.2147 - val_acc: 0.9389\n",
      "Epoch 7/15\n",
      "1188/1187 [==============================] - 23s 20ms/step - loss: 0.0571 - acc: 0.9878 - val_loss: 0.1836 - val_acc: 0.9463\n",
      "Epoch 8/15\n",
      "1188/1187 [==============================] - 23s 19ms/step - loss: 0.0551 - acc: 0.9879 - val_loss: 0.1891 - val_acc: 0.9463\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.010000000149011612.\n",
      "Epoch 9/15\n",
      "1188/1187 [==============================] - 23s 19ms/step - loss: 0.0451 - acc: 0.9907 - val_loss: 0.1695 - val_acc: 0.9547\n",
      "Epoch 10/15\n",
      "1188/1187 [==============================] - 23s 19ms/step - loss: 0.0417 - acc: 0.9915 - val_loss: 0.1497 - val_acc: 0.9557\n",
      "Epoch 11/15\n",
      "1188/1187 [==============================] - 23s 20ms/step - loss: 0.0374 - acc: 0.9925 - val_loss: 0.1551 - val_acc: 0.9579\n",
      "Epoch 12/15\n",
      "1188/1187 [==============================] - 23s 20ms/step - loss: 0.0345 - acc: 0.9933 - val_loss: 0.1405 - val_acc: 0.9547\n",
      "Epoch 13/15\n",
      "1188/1187 [==============================] - 23s 20ms/step - loss: 0.0362 - acc: 0.9932 - val_loss: 0.1532 - val_acc: 0.9600\n",
      "Epoch 14/15\n",
      "1188/1187 [==============================] - 23s 19ms/step - loss: 0.0344 - acc: 0.9932 - val_loss: 0.1421 - val_acc: 0.9610\n",
      "Epoch 15/15\n",
      "1188/1187 [==============================] - 23s 19ms/step - loss: 0.0365 - acc: 0.9926 - val_loss: 0.1968 - val_acc: 0.9484\n"
     ]
    }
   ],
   "source": [
    "train_model(train_img, train_label, test_img, test_label, model_path, start_='update')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_25 (InputLayer)        (None, 51, 51, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_169 (Conv2D)          (None, 49, 49, 64)        1792      \n",
      "_________________________________________________________________\n",
      "batch_normalization_217 (Bat (None, 49, 49, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_169 (LeakyReLU)  (None, 49, 49, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_170 (Conv2D)          (None, 47, 47, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_218 (Bat (None, 47, 47, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_170 (LeakyReLU)  (None, 47, 47, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_73 (MaxPooling (None, 23, 23, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_171 (Conv2D)          (None, 21, 21, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_219 (Bat (None, 21, 21, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_171 (LeakyReLU)  (None, 21, 21, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_172 (Conv2D)          (None, 19, 19, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_220 (Bat (None, 19, 19, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_172 (LeakyReLU)  (None, 19, 19, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_74 (MaxPooling (None, 9, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_173 (Conv2D)          (None, 7, 7, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_221 (Bat (None, 7, 7, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_173 (LeakyReLU)  (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_174 (Conv2D)          (None, 5, 5, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_222 (Bat (None, 5, 5, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_174 (LeakyReLU)  (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_175 (Conv2D)          (None, 3, 3, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_223 (Bat (None, 3, 3, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_175 (LeakyReLU)  (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_75 (MaxPooling (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_25 (Flatten)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_49 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_224 (Bat (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_50 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 12)                1548      \n",
      "_________________________________________________________________\n",
      "batch_normalization_225 (Bat (None, 12)                48        \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 12)                0         \n",
      "=================================================================\n",
      "Total params: 1,775,100\n",
      "Trainable params: 1,772,516\n",
      "Non-trainable params: 2,584\n",
      "_________________________________________________________________\n",
      "949/949 [==============================] - 2s 3ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'Sugar beet', 1: 'Common Chickweed', 2: 'Cleavers', 3: 'Shepherds Purse', 4: 'Charlock', 5: 'Common wheat', 6: 'Small-flowered Cranesbill', 7: 'Loose Silky-bent', 8: 'Scentless Mayweed', 9: 'Fat Hen', 10: 'Maize', 11: 'Black-grass'}\n"
     ]
    }
   ],
   "source": [
    "model_ = get_model()\n",
    "model_.load_weights(filepath = model_path + 'model_weight_SGD.hdf5')\n",
    "prob = model_.predict(test_img, verbose=1)\n",
    "pred = prob.argmax(axis=-1)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "best_confmat = confusion_matrix(np.array(test_label_for_cm), pred)\n",
    "total_bins = best_confmat.shape[0]\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "sum_rows = np.sum(best_confmat,axis=1) # this line is summing up the total ground-truth values that were accounted for. \n",
    "nonzero_axis = [i for i in range(len(sum_rows)) if sum_rows[i] !=0] # in case some classes were never predicted (maybe very sparse), then this \n",
    "                                                                    # makes it not so ugly\n",
    "scaled_confmat = best_confmat[nonzero_axis] / sum_rows[nonzero_axis,None] # if the distribution of classes were skewed, then the heatmap would \n",
    "                                                                          # be a bit awkward (bigger classes would get most of the color weight)\n",
    "\n",
    "plt.matshow(scaled_confmat)\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(total_bins)\n",
    "plt.xticks(tick_marks, range(total_bins))\n",
    "plt.yticks(tick_marks,nonzero_axis)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n",
    "print(ind2name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_26 (InputLayer)        (None, 51, 51, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_176 (Conv2D)          (None, 49, 49, 64)        1792      \n",
      "_________________________________________________________________\n",
      "batch_normalization_226 (Bat (None, 49, 49, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_176 (LeakyReLU)  (None, 49, 49, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_177 (Conv2D)          (None, 47, 47, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_227 (Bat (None, 47, 47, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_177 (LeakyReLU)  (None, 47, 47, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_76 (MaxPooling (None, 23, 23, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_178 (Conv2D)          (None, 21, 21, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_228 (Bat (None, 21, 21, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_178 (LeakyReLU)  (None, 21, 21, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_179 (Conv2D)          (None, 19, 19, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_229 (Bat (None, 19, 19, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_179 (LeakyReLU)  (None, 19, 19, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_77 (MaxPooling (None, 9, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_180 (Conv2D)          (None, 7, 7, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_230 (Bat (None, 7, 7, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_180 (LeakyReLU)  (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_181 (Conv2D)          (None, 5, 5, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_231 (Bat (None, 5, 5, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_181 (LeakyReLU)  (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_182 (Conv2D)          (None, 3, 3, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_232 (Bat (None, 3, 3, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_182 (LeakyReLU)  (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_78 (MaxPooling (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_26 (Flatten)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_51 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_233 (Bat (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_52 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 12)                1548      \n",
      "_________________________________________________________________\n",
      "batch_normalization_234 (Bat (None, 12)                48        \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 12)                0         \n",
      "=================================================================\n",
      "Total params: 1,775,100\n",
      "Trainable params: 1,772,516\n",
      "Non-trainable params: 2,584\n",
      "_________________________________________________________________\n",
      "794/794 [==============================] - 3s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "## test set\n",
    "\n",
    "def test_model():\n",
    "    test_imgs = glob.glob(test_dir + '/*')\n",
    "    \n",
    "    test_set = np.array([img_get(i) for i in test_imgs])\n",
    "    test_names = [i.replace(test_dir,'') for i in test_imgs]\n",
    "    \n",
    "    model_ = get_model()\n",
    "    model_.load_weights(filepath = model_path + 'model_weight_SGD.hdf5')\n",
    "    prob = model_.predict(test_set, verbose=1)\n",
    "    pred = prob.argmax(axis=-1)\n",
    "    sub = pd.DataFrame({\"file\": test_names,\n",
    "                         \"species\": [ind2name[p] for p in pred]})\n",
    "    #sub.to_csv(\"sub.csv\", index=False, header=True)\n",
    "    return sub\n",
    "\n",
    "output = test_model()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv('/home/bsong/Play/submissions/balanced_cnn_valacc9610.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_py3",
   "language": "python",
   "name": "venv_py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
