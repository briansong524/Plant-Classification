{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import numpy.core.defchararray as np_string\n",
    "import pandas as pd\n",
    "\n",
    "import glob\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_dir = os.getcwd() + '/kaggle_plants/'\n",
    "train_dir = work_dir + 'train/'\n",
    "test_dir = work_dir + 'test/'\n",
    "model_path = work_dir + 'model/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Common wheat', 'Scentless Mayweed', 'Sugar beet', 'Charlock', 'Maize', 'Black-grass', 'Common Chickweed', 'Fat Hen', 'Shepherds Purse', 'Loose Silky-bent', 'Cleavers', 'Small-flowered Cranesbill']\n"
     ]
    }
   ],
   "source": [
    "list_paths = glob.glob(train_dir + '*')\n",
    "list_names = [i.replace(train_dir,'') for i in list_paths]\n",
    "print(list_names)\n",
    "name2ind = dict(zip(list_names, range(len(list_names))))\n",
    "ind2name = dict(zip(range(len(list_names)),list_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common wheat: 221 pictures\n",
      "Scentless Mayweed: 516 pictures\n",
      "Sugar beet: 385 pictures\n",
      "Charlock: 390 pictures\n",
      "Maize: 221 pictures\n",
      "Black-grass: 263 pictures\n",
      "Common Chickweed: 611 pictures\n",
      "Fat Hen: 475 pictures\n",
      "Shepherds Purse: 231 pictures\n",
      "Loose Silky-bent: 654 pictures\n",
      "Cleavers: 287 pictures\n",
      "Small-flowered Cranesbill: 496 pictures\n"
     ]
    }
   ],
   "source": [
    "for i in list_names:\n",
    "    print(i + ': ' + str(len(os.listdir(train_dir + i))) + ' pictures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = list()\n",
    "train_label = list()\n",
    "test_set = list()\n",
    "test_label = list()\n",
    "\n",
    "for i in list_names:\n",
    "    glob_per_dir = glob.glob(train_dir + i + '/*')\n",
    "    n_plants = len(glob_per_dir)\n",
    "    n_train = int(np.round(0.8*n_plants))\n",
    "    train_path_per_glob = random.sample(glob_per_dir, n_train)\n",
    "    test_path_per_glob = list(set(glob_per_dir) - set(train_path_per_glob))\n",
    "    train_set.extend(train_path_per_glob)\n",
    "    test_set.extend(test_path_per_glob)\n",
    "    train_label.extend([i]*n_train)\n",
    "    test_label.extend([i]*(len(glob_per_dir) - n_train))\n",
    "    \n",
    "train_label = [name2ind[i] for i in train_label]\n",
    "test_label = [name2ind[i] for i in test_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsong/venv/py3/lib/python3.5/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/home/bsong/venv/py3/lib/python3.5/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    }
   ],
   "source": [
    "from skimage.transform import resize as imresize\n",
    "import imageio\n",
    "\n",
    "def img_reshape(img):\n",
    "    img = imresize(img, (51, 51, 3))\n",
    "    return img\n",
    "\n",
    "def img_get(path):\n",
    "    img = imageio.imread(path)\n",
    "    img = img_reshape(img)\n",
    "    return img\n",
    "train_img = [img_get(i) for i in train_set]\n",
    "test_img = [img_get(i) for i in test_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3801 3801\n"
     ]
    }
   ],
   "source": [
    "print(len(train_img), len(train_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, Input\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "import keras.backend as K\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "# Dense layers set\n",
    "def dense_set(inp_layer, n, activation, drop_rate=0.):\n",
    "    dp = Dropout(drop_rate)(inp_layer)\n",
    "    dns = Dense(n)(dp)\n",
    "    bn = BatchNormalization(axis=-1)(dns)\n",
    "    act = Activation(activation=activation)(bn)\n",
    "    return act\n",
    "\n",
    "# Conv. layers set\n",
    "def conv_layer(feature_batch, feature_map, kernel_size=(3, 3),strides=(1,1), zp_flag=False):\n",
    "    if zp_flag:\n",
    "        zp = ZeroPadding2D((1,1))(feature_batch)\n",
    "    else:\n",
    "        zp = feature_batch\n",
    "    conv = Conv2D(filters=feature_map, kernel_size=kernel_size, strides=strides)(zp)\n",
    "    bn = BatchNormalization(axis=3)(conv)\n",
    "    act = LeakyReLU(1/10)(bn)\n",
    "    return act\n",
    "\n",
    "# simple model \n",
    "def get_model():\n",
    "    inp_img = Input(shape=(51, 51, 3))\n",
    "\n",
    "    # 51\n",
    "    conv1 = conv_layer(inp_img, 64, zp_flag=False)\n",
    "    conv2 = conv_layer(conv1, 64, zp_flag=False)\n",
    "    mp1 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2))(conv2)\n",
    "    # 23\n",
    "    conv3 = conv_layer(mp1, 128, zp_flag=False)\n",
    "    conv4 = conv_layer(conv3, 128, zp_flag=False)\n",
    "    mp2 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2))(conv4)\n",
    "    # 9\n",
    "    conv7 = conv_layer(mp2, 256, zp_flag=False)\n",
    "    conv8 = conv_layer(conv7, 256, zp_flag=False)\n",
    "    conv9 = conv_layer(conv8, 256, zp_flag=False)\n",
    "    mp3 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2))(conv9)\n",
    "    # 1\n",
    "    # dense layers\n",
    "    flt = Flatten()(mp3)\n",
    "    ds1 = dense_set(flt, 128, activation='tanh')\n",
    "    out = dense_set(ds1, 12, activation='softmax')\n",
    "\n",
    "    model = Model(inputs=inp_img, outputs=out)\n",
    "    \n",
    "    # The first 50 epochs are used by Adam opt.\n",
    "    # Then 30 epochs are used by SGD opt.\n",
    "    \n",
    "    #mypotim = Adam(lr=2 * 1e-3, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "    mypotim = SGD(lr=1 * 1e-1, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                   optimizer=mypotim,\n",
    "                   metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "#model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "EPOCHS = 30\n",
    "RANDOM_STATE = 11\n",
    "\n",
    "def get_callbacks(filepath, patience=5):\n",
    "    lr_reduce = ReduceLROnPlateau(monitor='val_acc', factor=0.1, min_delta=1e-5, patience=patience, verbose=1)\n",
    "    msave = ModelCheckpoint(filepath, save_best_only=True)\n",
    "    return [lr_reduce, msave]\n",
    "\n",
    "def train_model(xtr,ytr,xte,yte, model_path):\n",
    "    \n",
    "    callbacks = get_callbacks(filepath = model_path + 'model_weight_SGD.hdf5', patience = 6)\n",
    "    model_ = get_model()\n",
    "    \n",
    "    gen = ImageDataGenerator(\n",
    "            rotation_range=360.,\n",
    "            width_shift_range=0.3,\n",
    "            height_shift_range=0.3,\n",
    "            zoom_range=0.3,\n",
    "            horizontal_flip=True,\n",
    "            vertical_flip=True\n",
    "            )\n",
    "    \n",
    "    model_.fit_generator(gen.flow(xtr,ytr, batch_size = BATCH_SIZE),\n",
    "                       steps_per_epoch=10*len(xtr)/BATCH_SIZE,\n",
    "                       epochs=EPOCHS,\n",
    "                       verbose=1,\n",
    "                       shuffle=True,\n",
    "                       validation_data=(xte, yte),\n",
    "                       callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 51, 51, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 49, 49, 64)        1792      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 49, 49, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 49, 49, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 47, 47, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 47, 47, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 47, 47, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 23, 23, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 21, 21, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 21, 21, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 21, 21, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 19, 19, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 19, 19, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 19, 19, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 9, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 7, 7, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 7, 7, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 5, 5, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 5, 5, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 3, 3, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 3, 3, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 12)                1548      \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 12)                48        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 12)                0         \n",
      "=================================================================\n",
      "Total params: 1,775,100\n",
      "Trainable params: 1,772,516\n",
      "Non-trainable params: 2,584\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "2376/2375 [==============================] - 30s 13ms/step - loss: 1.3202 - acc: 0.5490 - val_loss: 0.8855 - val_acc: 0.6881\n",
      "Epoch 2/30\n",
      "2376/2375 [==============================] - 28s 12ms/step - loss: 0.8046 - acc: 0.7247 - val_loss: 0.6979 - val_acc: 0.7724\n",
      "Epoch 3/30\n",
      "2376/2375 [==============================] - 28s 12ms/step - loss: 0.6401 - acc: 0.7804 - val_loss: 0.3855 - val_acc: 0.8599\n",
      "Epoch 4/30\n",
      "2376/2375 [==============================] - 28s 12ms/step - loss: 0.5344 - acc: 0.8128 - val_loss: 0.3487 - val_acc: 0.8662\n",
      "Epoch 5/30\n",
      "2376/2375 [==============================] - 28s 12ms/step - loss: 0.4713 - acc: 0.8370 - val_loss: 0.5136 - val_acc: 0.8177\n",
      "Epoch 6/30\n",
      "2376/2375 [==============================] - 28s 12ms/step - loss: 0.4162 - acc: 0.8535 - val_loss: 0.9815 - val_acc: 0.7018\n",
      "Epoch 7/30\n",
      "2376/2375 [==============================] - 28s 12ms/step - loss: 0.3798 - acc: 0.8663 - val_loss: 1.6746 - val_acc: 0.5269\n",
      "Epoch 8/30\n",
      "2376/2375 [==============================] - 28s 12ms/step - loss: 0.3587 - acc: 0.8744 - val_loss: 0.4244 - val_acc: 0.8462\n",
      "Epoch 9/30\n",
      "2376/2375 [==============================] - 28s 12ms/step - loss: 0.3272 - acc: 0.8851 - val_loss: 0.2501 - val_acc: 0.9020\n",
      "Epoch 10/30\n",
      "2376/2375 [==============================] - 28s 12ms/step - loss: 0.3089 - acc: 0.8884 - val_loss: 0.3201 - val_acc: 0.8778\n",
      "Epoch 11/30\n",
      "2376/2375 [==============================] - 28s 12ms/step - loss: 0.2925 - acc: 0.8951 - val_loss: 0.1987 - val_acc: 0.9283\n",
      "Epoch 12/30\n",
      "2376/2375 [==============================] - 28s 12ms/step - loss: 0.2732 - acc: 0.9034 - val_loss: 0.3662 - val_acc: 0.8588\n",
      "Epoch 13/30\n",
      "2376/2375 [==============================] - 28s 12ms/step - loss: 0.2604 - acc: 0.9055 - val_loss: 0.3949 - val_acc: 0.8525\n",
      "Epoch 14/30\n",
      "2376/2375 [==============================] - 28s 12ms/step - loss: 0.2460 - acc: 0.9121 - val_loss: 0.2943 - val_acc: 0.8915\n",
      "Epoch 15/30\n",
      "2376/2375 [==============================] - 28s 12ms/step - loss: 0.2417 - acc: 0.9134 - val_loss: 0.2542 - val_acc: 0.9136\n",
      "Epoch 16/30\n",
      "2376/2375 [==============================] - 28s 12ms/step - loss: 0.2280 - acc: 0.9178 - val_loss: 0.2698 - val_acc: 0.9073\n",
      "Epoch 17/30\n",
      "2376/2375 [==============================] - 28s 12ms/step - loss: 0.2186 - acc: 0.9224 - val_loss: 0.1840 - val_acc: 0.9357\n",
      "Epoch 18/30\n",
      "2376/2375 [==============================] - 28s 12ms/step - loss: 0.2093 - acc: 0.9242 - val_loss: 0.2320 - val_acc: 0.9178\n",
      "Epoch 19/30\n",
      "2376/2375 [==============================] - 28s 12ms/step - loss: 0.2006 - acc: 0.9277 - val_loss: 0.2302 - val_acc: 0.9168\n",
      "Epoch 20/30\n",
      "2376/2375 [==============================] - 28s 12ms/step - loss: 0.1953 - acc: 0.9291 - val_loss: 0.1926 - val_acc: 0.9305\n",
      "Epoch 21/30\n",
      "2376/2375 [==============================] - 28s 12ms/step - loss: 0.1868 - acc: 0.9322 - val_loss: 0.1454 - val_acc: 0.9431\n",
      "Epoch 22/30\n",
      "2376/2375 [==============================] - 29s 12ms/step - loss: 0.1886 - acc: 0.9322 - val_loss: 0.3750 - val_acc: 0.8778\n",
      "Epoch 23/30\n",
      "2376/2375 [==============================] - 29s 12ms/step - loss: 0.1754 - acc: 0.9363 - val_loss: 0.5780 - val_acc: 0.7924\n",
      "Epoch 24/30\n",
      "2376/2375 [==============================] - 29s 12ms/step - loss: 0.1765 - acc: 0.9367 - val_loss: 0.2530 - val_acc: 0.9189\n",
      "Epoch 25/30\n",
      "2376/2375 [==============================] - 29s 12ms/step - loss: 0.1665 - acc: 0.9401 - val_loss: 0.1705 - val_acc: 0.9420\n",
      "Epoch 26/30\n",
      "2376/2375 [==============================] - 29s 12ms/step - loss: 0.1596 - acc: 0.9428 - val_loss: 0.2093 - val_acc: 0.9399\n",
      "Epoch 27/30\n",
      "2376/2375 [==============================] - 29s 12ms/step - loss: 0.1655 - acc: 0.9418 - val_loss: 0.2692 - val_acc: 0.9062\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.010000000149011612.\n",
      "Epoch 28/30\n",
      "2376/2375 [==============================] - 29s 12ms/step - loss: 0.1181 - acc: 0.9572 - val_loss: 0.1262 - val_acc: 0.9600\n",
      "Epoch 29/30\n",
      "2376/2375 [==============================] - 29s 12ms/step - loss: 0.1030 - acc: 0.9620 - val_loss: 0.1189 - val_acc: 0.9642\n",
      "Epoch 30/30\n",
      "2376/2375 [==============================] - 29s 12ms/step - loss: 0.1034 - acc: 0.9624 - val_loss: 0.1232 - val_acc: 0.9557\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "train_img = np.array(train_img)\n",
    "test_img = np.array(test_img)\n",
    "train_label = to_categorical(np.array(train_label))\n",
    "test_label = to_categorical(np.array(test_label))\n",
    "train_model(train_img, train_label, test_img, test_label, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsong/venv/py3/lib/python3.5/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/home/bsong/venv/py3/lib/python3.5/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 51, 51, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 49, 49, 64)        1792      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 49, 49, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 49, 49, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 47, 47, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 47, 47, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 47, 47, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 23, 23, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 21, 21, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 21, 21, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 21, 21, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 19, 19, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 19, 19, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 19, 19, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 9, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 7, 7, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 7, 7, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 5, 5, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 5, 5, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 3, 3, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 3, 3, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 12)                1548      \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 12)                48        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 12)                0         \n",
      "=================================================================\n",
      "Total params: 1,775,100\n",
      "Trainable params: 1,772,516\n",
      "Non-trainable params: 2,584\n",
      "_________________________________________________________________\n",
      "794/794 [==============================] - 1s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "## test set\n",
    "\n",
    "def test_model():\n",
    "    test_imgs = glob.glob(test_dir + '/*')\n",
    "    \n",
    "    test_set = np.array([img_get(i) for i in test_imgs])\n",
    "    test_names = [i.replace(test_dir,'') for i in test_imgs]\n",
    "    \n",
    "    model_ = get_model()\n",
    "    model_.load_weights(filepath = model_path + 'model_weight_SGD.hdf5')\n",
    "    prob = model_.predict(test_set, verbose=1)\n",
    "    pred = prob.argmax(axis=-1)\n",
    "    sub = pd.DataFrame({\"file\": test_names,\n",
    "                         \"species\": [ind2name[p] for p in pred]})\n",
    "    #sub.to_csv(\"sub.csv\", index=False, header=True)\n",
    "    return sub\n",
    "\n",
    "output = test_model()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv('/home/bsong/kaggle_plants/submission_01.csv', index=False,)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3 venv",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
