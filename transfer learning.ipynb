{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "import random\n",
    "from math import ceil\n",
    "\n",
    "import numpy as np\n",
    "import numpy.core.defchararray as np_string\n",
    "import pandas as pd\n",
    "\n",
    "import glob\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_dir = os.getcwd() \n",
    "train_dir = work_dir + '/train/'\n",
    "test_dir = work_dir + '/test/'\n",
    "model_path = work_dir + '/model/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sugar beet', 'Common Chickweed', 'Cleavers', 'Shepherds Purse', 'Charlock', 'Common wheat', 'Small-flowered Cranesbill', 'Loose Silky-bent', 'Scentless Mayweed', 'Fat Hen', 'Maize', 'Black-grass']\n"
     ]
    }
   ],
   "source": [
    "list_paths = glob.glob(train_dir + '*')\n",
    "list_names = [i.replace(train_dir,'') for i in list_paths]\n",
    "print(list_names)\n",
    "name2ind = dict(zip(list_names, range(len(list_names))))\n",
    "ind2name = dict(zip(range(len(list_names)),list_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = list()\n",
    "train_label = list()\n",
    "test_set = list()\n",
    "test_label = list()\n",
    "\n",
    "for i in list_names:\n",
    "    glob_per_dir = glob.glob(train_dir + i + '/*')\n",
    "    n_plants = len(glob_per_dir)\n",
    "    n_train = int(np.round(0.8*n_plants))\n",
    "    train_path_per_glob = random.sample(glob_per_dir, n_train)\n",
    "    test_path_per_glob = list(set(glob_per_dir) - set(train_path_per_glob))\n",
    "    train_set.extend(train_path_per_glob)\n",
    "    test_set.extend(test_path_per_glob)\n",
    "    train_label.extend([i]*n_train)\n",
    "    test_label.extend([i]*(len(glob_per_dir) - n_train))\n",
    "\n",
    "train_label_list = [name2ind[i] for i in train_label]\n",
    "test_label_list = [name2ind[i] for i in test_label]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import resize as imresize\n",
    "import imageio\n",
    "\n",
    "def img_reshape(img):\n",
    "    img = imresize(img, (48, 48, 3))\n",
    "    return img\n",
    "\n",
    "def img_get(path):\n",
    "    img = imageio.imread(path)\n",
    "    img = img_reshape(img)\n",
    "    return img\n",
    "\n",
    "train_img = [img_get(i) for i in train_set]\n",
    "test_img = [img_get(i) for i in test_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras.utils import to_categorical\n",
    "train_img = np.array(train_img)\n",
    "test_img = np.array(test_img)\n",
    "train_label = to_categorical(np.array(train_label_list))\n",
    "test_label = to_categorical(np.array(test_label_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # model_final.summary()\n",
    "from keras import backend as K\n",
    "K.clear_session()\n",
    "# del train_model\n",
    "# del model_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model \n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras import backend as k \n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
    "\n",
    "img_width, img_height = 48,48\n",
    "pretrained_model = applications.VGG19(weights = \"imagenet\", include_top=False, input_shape = (img_width, img_height, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def balance_image_gen(list_names, train_dict, train_directory, BATCH_SIZE):\n",
    "#     small_n = int(ceil(BATCH_SIZE / len(list_names))) # random round up\n",
    "#     classes = [i for i in list_names for _ in range(small_n)]\n",
    "#     list_dir = map(lambda x: [random.choice(train_dict[x]) for _ in range(small_n)], list_names)\n",
    "#     list_dir = [item for sublist in list_dir for item in sublist]\n",
    "#     gen_df = pd.DataFrame({'filename':list_dir, 'class':classes})\n",
    "    \n",
    "#     gen = ImageDataGenerator(\n",
    "#         rotation_range=360.,\n",
    "#         width_shift_range=0.3,\n",
    "#         height_shift_range=0.3,\n",
    "#         zoom_range=0.3,\n",
    "#         horizontal_flip=True,\n",
    "#         vertical_flip=True\n",
    "#         )\n",
    "\n",
    "#     return gen.flow_from_dataframe(gen_df, train_directory, x_col='filename', y_col='class', has_ext=True, target_size=(51, 51), batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Activation\n",
    "\n",
    "for layer in pretrained_model.layers[:5]:\n",
    "    layer.trainable = False\n",
    "for layer in pretrained_model.layers[5:]:\n",
    "    layer.trainable = True\n",
    "    \n",
    "    \n",
    "x = pretrained_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(64, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(128, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(256, activation=\"relu\")(x)\n",
    "x = Dense(12)(x)\n",
    "predictions = Activation(activation='softmax')(x)\n",
    "\n",
    "# creating the final model \n",
    "model_final = Model(inputs = pretrained_model.input, outputs = predictions)\n",
    "\n",
    "# compile the model \n",
    "model_final.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.SGD(lr=0.0001, momentum=0.9, nesterov=True), metrics=[\"accuracy\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = dict(zip(range(len(list_names)), [1]*len(list_names)))\n",
    "class_weights[7] = 2\n",
    "class_weights[11] = .1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1188/1187 [==============================] - 23s 19ms/step - loss: 0.2510 - acc: 0.8893 - val_loss: 0.2830 - val_acc: 0.8851\n",
      "Epoch 2/200\n",
      "1188/1187 [==============================] - 23s 19ms/step - loss: 0.2409 - acc: 0.8865 - val_loss: 0.2674 - val_acc: 0.8988\n",
      "Epoch 3/200\n",
      "1188/1187 [==============================] - 23s 19ms/step - loss: 0.2363 - acc: 0.8890 - val_loss: 0.2841 - val_acc: 0.8957\n",
      "Epoch 4/200\n",
      "1188/1187 [==============================] - 23s 19ms/step - loss: 0.2313 - acc: 0.8871 - val_loss: 0.3028 - val_acc: 0.8841\n",
      "Epoch 5/200\n",
      "1188/1187 [==============================] - 23s 19ms/step - loss: 0.2301 - acc: 0.8920 - val_loss: 0.2736 - val_acc: 0.8988\n",
      "Epoch 6/200\n",
      "1188/1187 [==============================] - 23s 19ms/step - loss: 0.2222 - acc: 0.8936 - val_loss: 0.2591 - val_acc: 0.9041\n",
      "Epoch 7/200\n",
      "1188/1187 [==============================] - 23s 19ms/step - loss: 0.2275 - acc: 0.8892 - val_loss: 0.2735 - val_acc: 0.8967\n",
      "Epoch 8/200\n",
      "1188/1187 [==============================] - 23s 19ms/step - loss: 0.2239 - acc: 0.8933 - val_loss: 0.2443 - val_acc: 0.8946\n",
      "Epoch 9/200\n",
      "1188/1187 [==============================] - 23s 19ms/step - loss: 0.2223 - acc: 0.8924 - val_loss: 0.2924 - val_acc: 0.8978\n",
      "Epoch 10/200\n",
      "1188/1187 [==============================] - 23s 19ms/step - loss: 0.2208 - acc: 0.8920 - val_loss: 0.2659 - val_acc: 0.8978\n",
      "Epoch 11/200\n",
      "1188/1187 [==============================] - 23s 19ms/step - loss: 0.2300 - acc: 0.8897 - val_loss: 0.2463 - val_acc: 0.9031\n",
      "Epoch 12/200\n",
      "1188/1187 [==============================] - 23s 19ms/step - loss: 0.2137 - acc: 0.8929 - val_loss: 0.2658 - val_acc: 0.8978\n",
      "Epoch 13/200\n",
      "1188/1187 [==============================] - 23s 19ms/step - loss: 0.2172 - acc: 0.8942 - val_loss: 0.2661 - val_acc: 0.9020\n",
      "Epoch 14/200\n",
      "1188/1187 [==============================] - 23s 19ms/step - loss: 0.2117 - acc: 0.8932 - val_loss: 0.2680 - val_acc: 0.9009\n",
      "Epoch 15/200\n",
      "1188/1187 [==============================] - 23s 19ms/step - loss: 0.2237 - acc: 0.8905 - val_loss: 0.2706 - val_acc: 0.9009\n",
      "Epoch 16/200\n",
      "1188/1187 [==============================] - 23s 19ms/step - loss: 0.2189 - acc: 0.8921 - val_loss: 0.2714 - val_acc: 0.9052\n",
      "Epoch 17/200\n",
      "1188/1187 [==============================] - 23s 19ms/step - loss: 0.2086 - acc: 0.8943 - val_loss: 0.2801 - val_acc: 0.9031\n",
      "Epoch 18/200\n",
      "1188/1187 [==============================] - 23s 19ms/step - loss: 0.2171 - acc: 0.8929 - val_loss: 0.2736 - val_acc: 0.9041\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0d797b04a8>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 16\n",
    "EPOCHS = 200\n",
    "RANDOM_STATE = 11\n",
    "\n",
    "def get_callbacks(filepath, patience=5):\n",
    "    es = EarlyStopping('val_loss', patience=patience, mode=\"min\")\n",
    "    lr_reduce = ReduceLROnPlateau(monitor='val_acc', factor=0.5, min_delta=1e-5, patience=patience, verbose=1)\n",
    "    msave = ModelCheckpoint(filepath, save_best_only=True)\n",
    "    return [es, lr_reduce, msave]\n",
    "\n",
    "model_name = 'vgg19'\n",
    "callbacks = get_callbacks(filepath = model_path + model_name + '.hdf5', patience = 10)\n",
    "\n",
    "gen = ImageDataGenerator(\n",
    "            rotation_range=360.,\n",
    "            width_shift_range=0.3,\n",
    "            height_shift_range=0.3,\n",
    "            zoom_range=0.1,\n",
    "            horizontal_flip=True,\n",
    "            vertical_flip=True\n",
    "            )\n",
    "\n",
    "\n",
    "model_final.fit_generator(gen.flow(train_img, train_label, batch_size = BATCH_SIZE),\n",
    "                   steps_per_epoch=5*len(train_img)/BATCH_SIZE,\n",
    "                   epochs=EPOCHS,\n",
    "                   verbose=1,\n",
    "                   shuffle=True,\n",
    "                   validation_data=gen.flow(test_img, test_label, batch_size = BATCH_SIZE),\n",
    "                   validation_steps=len(test_img) / BATCH_SIZE,\n",
    "                   callbacks=callbacks,\n",
    "                   class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.utils import to_categorical\n",
    "# train_img = np.array(train_img)\n",
    "# test_img = np.array(test_img)\n",
    "# train_label = to_categorical(np.array(train_label))\n",
    "# test_label = to_categorical(np.array(test_label))\n",
    "\n",
    "# train_model(train_img, train_label, test_img, test_label, model_path, model_final, list_names, train_dict, train_dir, BATCH_SIZE, model_name = 'vgg19')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "949/949 [==============================] - 0s 257us/step\n"
     ]
    }
   ],
   "source": [
    "prob = model_final.predict(test_img, verbose=1)\n",
    "pred = prob.argmax(axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(949,)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(test_label_list).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "best_confmat = confusion_matrix(np.array(test_label_list), pred)\n",
    "total_bins = best_confmat.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'Sugar beet', 1: 'Common Chickweed', 2: 'Cleavers', 3: 'Shepherds Purse', 4: 'Charlock', 5: 'Common wheat', 6: 'Small-flowered Cranesbill', 7: 'Loose Silky-bent', 8: 'Scentless Mayweed', 9: 'Fat Hen', 10: 'Maize', 11: 'Black-grass'}\n"
     ]
    }
   ],
   "source": [
    "### Printing heat map of confusion matrix (PHMCM) ###\n",
    "# assume the confusion matrix is stored under \"best_confmat\"\n",
    "# also required is total number of bins (here is labeled \"total_bins\")\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "sum_rows = np.sum(best_confmat,axis=1) # this line is summing up the total ground-truth values that were accounted for. \n",
    "nonzero_axis = [i for i in range(len(sum_rows)) if sum_rows[i] !=0] # in case some classes were never predicted (maybe very sparse), then this \n",
    "                                                                    # makes it not so ugly\n",
    "scaled_confmat = best_confmat[nonzero_axis] / sum_rows[nonzero_axis,None] # if the distribution of classes were skewed, then the heatmap would \n",
    "                                                                          # be a bit awkward (bigger classes would get most of the color weight)\n",
    "\n",
    "plt.matshow(scaled_confmat)\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(total_bins)\n",
    "plt.xticks(tick_marks, range(total_bins))\n",
    "plt.yticks(tick_marks,nonzero_axis)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n",
    "print(ind2name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## test set\n",
    "\n",
    "def test_model(model_name = 'model_weight_SGD'):\n",
    "    test_imgs = glob.glob(test_dir + '/*')\n",
    "    \n",
    "    test_set = np.array([img_get(i) for i in test_imgs])\n",
    "    test_names = [i.replace(test_dir,'') for i in test_imgs]\n",
    "    \n",
    "    model_ = model_final\n",
    "    model_.load_weights(filepath = model_path + model_name + '.hdf5')\n",
    "    prob = model_.predict(test_set, verbose=1)\n",
    "    pred = prob.argmax(axis=-1)\n",
    "    sub = pd.DataFrame({\"file\": test_names,\n",
    "                         \"species\": [ind2name[p] for p in pred]})\n",
    "    #sub.to_csv(\"sub.csv\", index=False, header=True)\n",
    "    return sub\n",
    "\n",
    "output = test_model(model_name = model_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv(os.getcwd() + '/transfer_learning_ResNet50_balanced.csv', index=False,)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_py3",
   "language": "python",
   "name": "venv_py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
